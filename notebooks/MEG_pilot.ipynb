{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "MEG Pilot\n",
      "=========\n",
      "\n",
      "The project should be in a directory with the following subdirectories:  \n",
      "\n",
      "-scripts/: importable scripts  \n",
      "-MEG_data/: MEG data and epoch alignment files  \n",
      "-notebooks/: This file and other associated ipython notebooks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Imports\n",
      "--------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Permit inline plotting\n",
      "%pylab inline\n",
      "\n",
      "#Do basic imports\n",
      "from __future__ import division\n",
      "import sys, os\n",
      "import scipy\n",
      "import pylab as pl\n",
      "import numpy as np\n",
      "import numpy.lib.recfunctions as recfunctions\n",
      "#from ptsa.data.bvwrapper import BVWrapper\n",
      "#from ptsa.plotting.topo import topoplot\n",
      "\n",
      "#change to the scripts directory to permit importing from there\n",
      "%cd ../scripts\n",
      "import protoReadExtractEEGlab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n",
        "/media/webley/Stacked Data/Documents/Work/meg_playground/scripts"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Definitions\n",
      "-----------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Definitions\n",
      "def adjustR2(R2, numFeatures, numSamples):\n",
      "        #1/0                                                               \n",
      "        #return R2                                                         \n",
      "        return R2-(1-R2)*(float(numFeatures)/(numSamples-numFeatures-1))\n",
      "\n",
      "def mynormalise(A):\n",
      "        A = scipy.stats.zscore(A)\n",
      "        A[numpy.isnan(A)] = 0\n",
      "        return A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load Data\n",
      "---------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#change to the data directory to load in the data\n",
      "%cd ../MEG_data\n",
      "\n",
      "#load MEG data\n",
      "(rawSignalData, metadata, trials, epochedSignalData, epochSliceTimepoints) = \\\n",
      "    protoReadExtractEEGlab.load('aud_hofd_a_allRuns_tsss_audiobookPrepro_stPad1_lp50_resamp125_frac10ICAed.set',[])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/media/webley/Stacked Data/Documents/Work/meg_playground/MEG_data\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#load alignment data\n",
      "wordPropsFile = 'hod_JoeTimes_LoadsaFeaturesV3.tab'                   \n",
      "wordProps = scipy.genfromtxt(wordPropsFile,delimiter='\\t',names=True,\\\n",
      "                             dtype=\"i4,f4,f4,S50,S50,i2,i2,i2,S10,f4,f4,f4,f4,f4,f4,f4,f4,f4,f4,f4\")\n",
      "print(wordProps.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(14595,)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Play\n",
      "-------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point, the following data structures are active:  \n",
      "\n",
      "    wordProps: ndarray of word-level properties\n",
      "    rawSignalData: ndarray w/ one row per channel and one column per timeslice\n",
      "    metadata: matlab.iostruct: use metadata._fieldnames to find colnames\n",
      "    trials:  empty\n",
      "    epochedSignalData:  empty\n",
      "    epochedSliceTimepoints:  empty"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wordProps exploration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(wordProps.dtype.names)\n",
      "print(wordProps['asrToken'][0:50])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('track', 'onTime', 'offTime', 'asrToken', 'annotToken', 'sentenceSerial', 'runSerial', 'storySerial', 'stanfPOS', 'lenLett', 'lenPhonCMU', 'lenSyllCMU', 'logFreq_ANC', 'bigramLogProbBack_COCA', 'trigramLogProbBack_COCA', 'surprisal2back_COCA', 'tokenPrimed', 'tokenPosPrimed', 'bigramEntropy_COCA_previous', 'bigramEntropy_COCA_here')\n",
        "['<SENT-END>' 'ONE' 'EVENING' 'AS' 'I' 'WAS' 'LYING' 'FLAT' 'ON' 'THE'\n",
        " 'DECK' 'OF' 'MY' 'STEAMBOAT' '<SPACE>' 'I' 'HEARD' 'VOICES' 'APPROACHING'\n",
        " '<SPACE>' 'AND' 'THERE' 'WERE' 'THE' 'NEPHEW' 'AND' 'THE' 'UNCLE'\n",
        " 'STROLLING' 'ALONG' 'THE' 'BANK' '<SENT-END>' 'I' 'LAID' 'MY' 'HEAD' 'ON'\n",
        " 'MY' 'ARM' 'AGAIN' '<SPACE>' 'AND' 'HAD' 'NEARLY' 'LOST' 'MYSELF' 'IN' 'A'\n",
        " 'DOZE']\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(wordProps['onTime'])\n",
      "print(mean(wordProps['onTime']))\n",
      "print(wordProps['track'])\n",
      "print(len(wordProps[wordProps['track']==5]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  3.40000018e-02   1.05400002e+00   1.32400000e+00 ...,   6.76174011e+02\n",
        "   6.76283997e+02   6.76963989e+02]\n",
        "299.449\n",
        "[1 1 1 ..., 8 8 8]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1781\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Alignment option 1: adding a modifier to the onset and offset times\n",
      "#  to get them in the same domain as the raw data\n",
      "\n",
      "prevt = 0.0\n",
      "timemod = 0\n",
      "\n",
      "newWordProps = np.copy(wordProps)\n",
      "\n",
      "for ti,t in enumerate(wordProps['onTime']):\n",
      "    if t < prevt:\n",
      "        #assume the final sample of a session doesn't occur after the final wordProps row\n",
      "        timemod += wordProps['offTime'][ti-1]  \n",
      "    newWordProps['onTime'][ti] += timemod\n",
      "    newWordProps['offTime'][ti] += timemod\n",
      "    prevt = t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(newWordProps['onTime'])\n",
      "print(mean(newWordProps['onTime']))\n",
      "print(newWordProps['track'])\n",
      "print(len(newWordProps[newWordProps['track']==5]))\n",
      "\n",
      "prevt = 1\n",
      "for ti,t in enumerate(wordProps['track']):\n",
      "    if t != prevt:\n",
      "        #boundary zone differences... they aren't flush because the first word of each session has some lead-in\n",
      "        #but it's important to also note that they don't line up with the metadata.event.latency list below...\n",
      "        print newWordProps['offTime'][ti-1], newWordProps['onTime'][ti]\n",
      "    prevt = t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  3.40000018e-02   1.05400002e+00   1.32400000e+00 ...,   6.89766406e+03\n",
        "   6.89777393e+03   6.89845361e+03]\n",
        "3736.34\n",
        "[1 1 1 ..., 8 8 8]\n",
        "1781\n",
        "445.404 445.438\n",
        "2687.61 2687.65\n",
        "3251.72 3251.75\n",
        "3777.42 3777.45\n",
        "4433.91 4433.94\n",
        "5322.31 5322.34\n",
        "6221.49 6221.52\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "metadata exploration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(metadata._fieldnames)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['setname', 'filename', 'filepath', 'subject', 'group', 'condition', 'session', 'comments', 'nbchan', 'trials', 'pnts', 'srate', 'xmin', 'xmax', 'times', 'data', 'icaact', 'icawinv', 'icasphere', 'icaweights', 'icachansind', 'chanlocs', 'urchanlocs', 'chaninfo', 'ref', 'event', 'urevent', 'eventdescription', 'epoch', 'epochdescription', 'reject', 'stats', 'specdata', 'specicaact', 'splinefile', 'icasplinefile', 'dipfit', 'history', 'saved', 'etc', 'datfile']\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(metadata.chanlocs[0]._fieldnames)\n",
      "print(metadata.chanlocs[0].labels)\n",
      "print(rawSignalData.shape[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['labels', 'ref', 'theta', 'radius', 'X', 'Y', 'Z', 'sph_theta', 'sph_phi', 'sph_radius', 'type', 'urchan']\n",
        "MEG0113\n",
        "588038\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(metadata.pnts)\n",
      "print(metadata.srate)\n",
      "print(metadata.times/1000)\n",
      "print(mean(metadata.times)/1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "588038\n",
        "125\n",
        "[ -0.00000000e+00   8.00000000e-03   1.60000000e-02 ...,   4.70428000e+03\n",
        "   4.70428800e+03   4.70429600e+03]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2352.148\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for event in metadata.event:\n",
      "    print(event.type, event.latency)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'boundary', 0.5)\n",
        "(u's1', 125.99999999999977)\n",
        "(u'e1', 55865)\n",
        "(u'boundary', 55990.5)\n",
        "(u's2', 56115.99999999999)\n",
        "(u'e2', 150082.875)\n",
        "(u'boundary', 150208.5)\n",
        "(u's3', 150333.99999999997)\n",
        "(u'e3', 220933.87499999997)\n",
        "(u'boundary', 221059.06249999997)\n",
        "(u's4', 221184.99999999994)\n",
        "(u'e4', 286949.125)\n",
        "(u'boundary', 287074.5)\n",
        "(u's5', 287200)\n",
        "(u'e5', 356377.625)\n",
        "(u'boundary', 356502.8125000001)\n",
        "(u's6', 356628.0000000001)\n",
        "(u'e6', 425840.6250000001)\n",
        "(u'boundary', 425965.8125000001)\n",
        "(u's7', 426091.0000000001)\n",
        "(u'e7', 502837.5000000001)\n",
        "(u'boundary', 502962.68750000035)\n",
        "(u's8', 503088.00000000035)\n",
        "(u'e8', 587913.6250000002)\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "rawSignalData exploration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(rawSignalData.shape)\n",
      "print(rawSignalData.dtype)\n",
      "print(epochedSignalData.shape)\n",
      "print(epochedSignalData.dtype)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(307, 588038)\n",
        "float32\n",
        "(0, 307)\n",
        "float32\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Work\n",
      "-------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get session-level stretches"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#adapted from protoReadExtractEEGlab.py\n",
      "\n",
      "triggersOfInterest = []\n",
      "for n in range(1,9):\n",
      "    triggersOfInterest += ['s'+str(n),'e'+str(n)]\n",
      "eLDS = metadata\n",
      "sessionStartSec = 0 #number of seconds to include before each session (needed to get lead-in for early word epochs)\n",
      "sessionEndSec = 1 #number of seconds to include after each session (needed to get lead-out for late word epochs)\n",
      "\n",
      "trialTriggers = []; # list of triggers\n",
      "trialLatencies = []; # ... and their latencies in timepoints (aka samples) to make record array of trials\n",
      "sessionSliceTimepoints = []; # embedded lists containing indices for each epoch\n",
      "sessionStartTimepoints = round(sessionStartSec*eLDS.srate) # number of timepoints (aka samples) before trigger to include in session\n",
      "sessionEndTimepoints = round(sessionEndSec*eLDS.srate) # ... ditto after the trigger\n",
      "mystart = 0.0\n",
      "myend = 0.0\n",
      "for event in eLDS.event:        \n",
      "# how to see stucture of one trigger: [(a, eval(\"eLDS.event[0].%s\" % a)) for a in dir(eLDS.event[0]) if not a.startswith('_')]\n",
      "    if event.type in triggersOfInterest:\n",
      "        if event.type[0] == 's':\n",
      "            #start event\n",
      "            mystart = event.latency + sessionStartTimepoints\n",
      "        else:\n",
      "            sessionSliceTimepoints.append(range(int(round(mystart)),int(round(event.latency+sessionEndTimepoints))))\n",
      "        #trialTriggers.append(event.type)\n",
      "        #trialLatencies.append(event.latency)\n",
      "        #sessionSliceTimepoints.append(range(int(round(prevlatency)),int(round(event.latency))))\n",
      "\n",
      "# create record array of trial IDs and their position in samples of the recording, allows field and entry-wise referencing: trials.timepoint, trials[5], trials[5].trigger, trials.trigger[5]\n",
      "#trials = np.core.records.fromarrays([trialTriggers, trialLatencies],names='trigger,timepoint')\n",
      "#L.info('Extracted %d trials of interest, with epochs running from %-.2fs to %+.2fs relative to triggers' % (len(trials), sessionStartSec, sessionEndSec))\n",
      "# create session-based view on data, using sessions of particular type\n",
      "\n",
      "#sessionedSignalData = rawSignalData[:,sessionSliceTimepoints[0]]#.swapaxes(0,1) # sessions x channels x timepoints\n",
      "#print(sessionSliceTimepoints[-1][-1])\n",
      "for l in sessionSliceTimepoints:\n",
      "    print(len(l))\n",
      "    \n",
      "sessionedSignalData = []#list(rawSignalData[:,sessionSliceTimepoints[0]])\n",
      "for sitting in sessionSliceTimepoints[:-1]: #range(1,len(sessionSliceTimepoints)-1):\n",
      "    #sessionedSignalData.append(list(rawSignalData[:,sessionSliceTimepoints[sitting]]))\n",
      "    sessionedSignalData.append(list(rawSignalData[:,sitting]))\n",
      "\n",
      "#the final timeslice ends after the last sample, so omit it\n",
      "sessionedSignalData.append(list(rawSignalData[:,sessionSliceTimepoints[-1][:-1]]))\n",
      "#sessionedSignalData = rawSignalData[:,sessionSliceTimepoints]#.swapaxes(0,1)\n",
      "\n",
      "print('----')\n",
      "for sit in sessionedSignalData:\n",
      "    print(len(sit),len(sit[0]))\n",
      "\n",
      "#current view is session x channel x sample\n",
      "#pick a channel, say 113, then epoch just that channel for this preliminary stuff"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "55864\n",
        "94092\n",
        "70725\n",
        "65889\n",
        "69303\n",
        "69338\n",
        "76872\n",
        "84951\n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(307, 55864)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(307, 94092)\n",
        "(307, 70725)\n",
        "(307, 65889)\n",
        "(307, 69303)\n",
        "(307, 69338)\n",
        "(307, 76872)\n",
        "(307, 84950)\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sit in sessionedSignalData:\n",
      "    print(sit[0][0:10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  6.17254945e-12   6.11931296e-12   1.36693781e-12  -3.08979686e-12\n",
        "  -2.50620661e-12  -2.73018413e-12  -5.97545451e-12  -6.97526759e-12\n",
        "  -3.75410814e-12  -3.13188928e-12]\n",
        "[ -1.62532227e-11  -1.34842163e-11  -1.12523159e-11  -1.34263043e-11\n",
        "  -1.93062979e-11  -1.85832304e-11  -1.37902805e-11  -1.27745705e-11\n",
        "  -1.07362010e-11  -7.75561646e-12]\n",
        "[ -1.07671511e-11  -1.06840257e-11  -1.52687637e-11  -1.65780133e-11\n",
        "  -1.47737308e-11  -1.33857586e-11  -1.46486052e-11  -1.51999021e-11\n",
        "  -1.47199995e-11  -1.48809923e-11]\n",
        "[  6.65713058e-12   3.93415248e-12  -4.56732829e-12  -1.32479574e-11\n",
        "  -1.42655610e-11  -6.42588803e-12   4.15774143e-12   8.18270712e-12\n",
        "  -3.35470746e-13  -1.01489954e-11]\n",
        "[  8.20967860e-12   7.01449359e-12   4.91032345e-12   1.31045663e-12\n",
        "   1.35004594e-12   5.95377220e-12   7.52772844e-12   7.67418681e-12\n",
        "   1.01015576e-11   8.65426567e-12]\n",
        "[  3.53339190e-12   4.48985640e-12   3.22289222e-12   4.25144555e-12\n",
        "   7.92016713e-12   1.28682230e-11   1.15218798e-11   5.51289006e-12\n",
        "   3.43023028e-12   1.73977065e-12]\n",
        "[  4.44983980e-12   5.34656954e-12   7.31456042e-12   8.35117305e-12\n",
        "   1.10943164e-11   1.46087534e-11   1.35914847e-11   6.89525433e-12\n",
        "   2.01742269e-13   1.35568889e-12]\n",
        "[ -7.34207226e-12   5.29593838e-13   4.36068499e-12   8.54629464e-13\n",
        "  -2.71335016e-12  -3.60461595e-12  -4.96962367e-12  -5.29613593e-12\n",
        "  -3.48688743e-12  -6.12990398e-13]\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Find the desired channel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#The broca-ish sensors are 0211,0212,0213\n",
      "# 0211: magnetometer\n",
      "# 0212: rostral gradiometer\n",
      "# 0213: caudal gradiometer\n",
      "chanids = [i for i in range(len(metadata.chanlocs)) if metadata.chanlocs[i].labels in \\\n",
      "           ('MEG0211','MEG0212','MEG0213')]\n",
      "print(chanids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[12, 13, 14]\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Align session samples to word-level epochs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(len(wordProps[wordProps['track']==1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1414\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epochedWordSamples = [] #has to be a list rather than a np.array because sessions have diff numbers of words; ragged\n",
      "prevtrack = 1\n",
      "previx = 0 #a marker that notes the last grabbed sample\n",
      "sampsum = 0\n",
      "for i,track in enumerate(wordProps['track']):\n",
      "    if track != prevtrack:\n",
      "        #we're in a new session\n",
      "        #presume the new session started immediately after the old session ended\n",
      "        #timemod -= wordProps['offTime'][i-1]\n",
      "        sampsum += previx\n",
      "        previx = 0\n",
      "    prevtrack = track\n",
      "    duration = int(round((wordProps['offTime'][i]-wordProps['onTime'][i]) * metadata.srate)) #number of samples for this word\n",
      "    \n",
      "    chanEpoch = [] #has to be a list rather than a np.array because words have diff numbers of samples; ragged\n",
      "    for chanid in chanids:\n",
      "        if i == len(wordProps['track'])-1:\n",
      "            print('i-1:',track-1, ' chanid:',chanid,\n",
      "                ' ix0:',previx,' ix1:',previx+duration)\n",
      "        #try:\n",
      "        chanEpoch.append(sessionedSignalData[track-1][chanid][previx:previx+duration])\n",
      "            #chanEpoch.append(sessionedSignalData[i-1][chanid][previx:previx+duration])\n",
      "        #except:\n",
      "        #    raise\n",
      "    epochedWordSamples.append(chanEpoch) #add the channel-based info to the epoch info\n",
      "    previx += duration #update the sample use history\n",
      "    \n",
      "#current view is word-epoch x channel x sample\n",
      "#can find out which epochs are at the session boundaries using the wordProps['track']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('i-1:', 7, ' chanid:', 12, ' ix0:', 84625, ' ix1:', 84750)\n",
        "('i-1:', 7, ' chanid:', 13, ' ix0:', 84625, ' ix1:', 84750)\n",
        "('i-1:', 7, ' chanid:', 14, ' ix0:', 84625, ' ix1:', 84750)\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print((sum(len(t[0]) for t in sessionedSignalData)-sampsum)/metadata.srate) #missing seconds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "690.136\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}